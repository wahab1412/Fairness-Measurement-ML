{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import models\n",
    "import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import scipy\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the models on the 3 datasets\n",
    "\n",
    "datasets = ['law_school_edited','crime_edited','insurance_edited']\n",
    "results_data = []\n",
    "for d in datasets:\n",
    "    results_data.append(models.train_models(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring fairness using a set of fairness metrics.\n",
    "\n",
    "fairness_results = []\n",
    "for result_data in results_data:\n",
    "    parity_list = []\n",
    "    indep_list = []\n",
    "    sep_list = []\n",
    "    dpd_list = []\n",
    "    hgr_ind_list = []\n",
    "    hgr_sep_list = []\n",
    "\n",
    "    protected_list = result_data[result_data.columns[-2]].values\n",
    "\n",
    "\n",
    "    for col in result_data.columns[:-2]:\n",
    "        parity = metrics.calc_demographic_parity_disparity(result_data[col].values, protected_list)\n",
    "        parity_list.append(round(parity,2))\n",
    "\n",
    "        metric = metrics.calculate_regression_measures(result_data['y_test'].values, result_data[col].values,protected_list,1)\n",
    "        indep_list.append(round(metric['independence'].values[0],2))\n",
    "        sep_list.append(round(metric['separation'].values[0],2))\n",
    "\n",
    "\n",
    "\n",
    "        f = metrics.optimized_f_fai(result_data[col].values, protected_list)\n",
    "        dpd_list.append(round(f,2))\n",
    "\n",
    "        hgr_ind_list.append(float(metrics.hgr(torch.Tensor(result_data[col].values), torch.Tensor(protected_list))))\n",
    "\n",
    "        metric = metrics.hgr_cond(torch.Tensor(result_data[col].values),torch.Tensor(protected_list),torch.Tensor(result_data['y_test'].values))\n",
    "        hgr_sep_list.append(np.max(metric))\n",
    "\n",
    "    fairness_results.append(pd.DataFrame({'Model': result_data.columns[:-2], 'DP1': parity_list, 'DP2': dpd_list, 'Independence': indep_list, 'DP3': hgr_ind_list, 'Separation': sep_list, 'Equalized Odds': hgr_sep_list}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Spearman's rank correlation and Pearson's correlation coefficient \n",
    "\n",
    "col1 = 'DP1'\n",
    "col2 = 'DP2'\n",
    "\n",
    "dataset = fairness_results[0]\n",
    "spearman_corr, spearman_p_value = scipy.stats.spearmanr(dataset[col1],dataset[col2])\n",
    "\n",
    "pearson_corr, pearson_p_value = scipy.stats.pearsonr(dataset[col1],dataset[col2])\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "spearman_significant = spearman_p_value < alpha\n",
    "pearson_significant = pearson_p_value < alpha\n",
    "\n",
    "\n",
    "result = f\"\"\"Pearson's Correlation Coefficient: {pearson_corr:.5f}\n",
    "- Statistically Significant: {\"True \" if pearson_significant else \" False\"}\n",
    "\n",
    "Spearman's Correlation Coefficient: {spearman_corr:.5f} \n",
    "- Statistically Significant: {\"True \" if  spearman_significant else \" False\"}\"\"\"\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting fairness values for a pair of metrics\n",
    "\n",
    "col1 = 'Separation'\n",
    "col2 = 'Equalized Odds'\n",
    "\n",
    "col1_val = fairness_results[0][col1] \n",
    "col2_val = fairness_results[0][col2]\n",
    "plt.scatter( col2_val,col1_val, color='blue', alpha=0.8,label='Law Dataset', marker='o')\n",
    "\n",
    "col1_val = fairness_results[1][col1] \n",
    "col2_val = fairness_results[1][col2]\n",
    "plt.scatter( col2_val,col1_val, color='red', alpha=0.8, label='Crime Dataset',marker='^')\n",
    "\n",
    "col1_val = fairness_results[2][col1] \n",
    "col2_val = fairness_results[2][col2]\n",
    "plt.scatter( col2_val,col1_val, color='green', alpha=0.8, label='Insurance Dataset', marker='d')\n",
    "\n",
    "\n",
    "plt.xlabel(col2)\n",
    "plt.ylabel(col1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housing_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
